{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Chapter 1: Data Structures & Complexity Refresher\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jmamath/openai-interview-textbook/blob/main/chapter_01_data_structures_complexity.ipynb)\n",
        "\n",
        "## Learning Objectives\n",
        "By the end of this chapter, you will be able to:\n",
        "- Analyze time and space complexity of algorithms\n",
        "- Understand memory layout and cache effects in ML operations\n",
        "- Compare vectorized operations vs loops for performance\n",
        "- Implement memory-efficient algorithms for large-scale ML\n",
        "- Profile and optimize memory usage in PyTorch/TensorFlow\n",
        "\n",
        "## Prerequisites\n",
        "- Basic understanding of Python and NumPy\n",
        "- Familiarity with PyTorch tensors\n",
        "- Knowledge of basic data structures (arrays, lists, dictionaries)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.1 Complexity Analysis Refresher\n",
        "\n",
        "### Big O Notation\n",
        "Big O notation describes the worst-case time or space complexity of an algorithm as the input size grows.\n",
        "\n",
        "**Common Complexities:**\n",
        "- O(1) - Constant time (array access, hash table lookup)\n",
        "- O(log n) - Logarithmic (binary search, balanced tree operations)\n",
        "- O(n) - Linear (single pass through array)\n",
        "- O(n log n) - Linearithmic (efficient sorting algorithms)\n",
        "- O(n¬≤) - Quadratic (nested loops)\n",
        "- O(2‚Åø) - Exponential (recursive Fibonacci)\n",
        "\n",
        "### Space Complexity\n",
        "Space complexity measures the amount of memory an algorithm uses relative to input size:\n",
        "- **Auxiliary space**: Extra space used by the algorithm\n",
        "- **Total space**: Input space + auxiliary space\n",
        "\n",
        "### Amortized Analysis\n",
        "Some operations may occasionally be expensive but are cheap on average:\n",
        "- Dynamic array resizing: O(1) amortized insertion\n",
        "- Hash table with chaining: O(1) amortized lookup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.2 Memory Layout and Cache Effects\n",
        "\n",
        "### Memory Hierarchy\n",
        "Modern computers have multiple levels of memory with different speeds and sizes:\n",
        "\n",
        "1. **CPU Registers** (fastest, smallest)\n",
        "2. **L1 Cache** (~32KB, ~1 cycle)\n",
        "3. **L2 Cache** (~256KB, ~10 cycles)\n",
        "4. **L3 Cache** (~8MB, ~40 cycles)\n",
        "5. **RAM** (~16GB, ~200 cycles)\n",
        "6. **Storage** (SSD/HDD, ~100,000+ cycles)\n",
        "\n",
        "### Cache Locality\n",
        "**Spatial Locality**: Accessing nearby memory locations\n",
        "**Temporal Locality**: Accessing the same memory location repeatedly\n",
        "\n",
        "### Row-Major vs Column-Major Ordering\n",
        "```python\n",
        "# Row-major (C-style): elements in same row are adjacent\n",
        "arr[i][j] and arr[i][j+1] are adjacent in memory\n",
        "\n",
        "# Column-major (Fortran-style): elements in same column are adjacent\n",
        "arr[i][j] and arr[i+1][j] are adjacent in memory\n",
        "```\n",
        "\n",
        "### Memory Access Patterns in ML\n",
        "- **Sequential access** is much faster than random access\n",
        "- **Vectorized operations** leverage SIMD instructions\n",
        "- **Memory bandwidth** often limits performance more than compute\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.3 Vectorization vs Loops\n",
        "\n",
        "### Why Vectorization is Faster\n",
        "1. **SIMD Instructions**: Single Instruction, Multiple Data\n",
        "2. **Reduced Python overhead**: Less interpreter calls\n",
        "3. **Better cache utilization**: Sequential memory access\n",
        "4. **Optimized C implementations**: NumPy/PyTorch use optimized BLAS\n",
        "\n",
        "### Example: Element-wise Operations\n",
        "```python\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Large array\n",
        "arr = np.random.randn(1000000)\n",
        "\n",
        "# Loop version (slow)\n",
        "def loop_sum(arr):\n",
        "    total = 0\n",
        "    for x in arr:\n",
        "        total += x\n",
        "    return total\n",
        "\n",
        "# Vectorized version (fast)\n",
        "def vectorized_sum(arr):\n",
        "    return np.sum(arr)\n",
        "\n",
        "# Vectorized is ~100x faster for large arrays\n",
        "```\n",
        "\n",
        "### When to Use Each Approach\n",
        "- **Use loops for**: Complex logic, small arrays, irregular patterns\n",
        "- **Use vectorization for**: Mathematical operations, large arrays, regular patterns\n",
        "- **Hybrid approach**: Vectorize outer loops, keep inner logic readable\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.4 Memory-Efficient Algorithms\n",
        "\n",
        "### In-Place Operations\n",
        "Modify data structures without creating copies:\n",
        "```python\n",
        "# In-place: O(1) extra space\n",
        "def reverse_inplace(arr):\n",
        "    left, right = 0, len(arr) - 1\n",
        "    while left < right:\n",
        "        arr[left], arr[right] = arr[right], arr[left]\n",
        "        left += 1\n",
        "        right -= 1\n",
        "\n",
        "# Not in-place: O(n) extra space\n",
        "def reverse_copy(arr):\n",
        "    return arr[::-1]\n",
        "```\n",
        "\n",
        "### Memory-Efficient Data Structures\n",
        "- **Sparse matrices**: Store only non-zero elements\n",
        "- **Compressed representations**: Use bit packing, run-length encoding\n",
        "- **Lazy evaluation**: Compute values on-demand\n",
        "- **Streaming algorithms**: Process data in chunks\n",
        "\n",
        "### Memory Profiling Tools\n",
        "```python\n",
        "import tracemalloc\n",
        "import psutil\n",
        "import torch\n",
        "\n",
        "# PyTorch memory tracking\n",
        "torch.cuda.memory_allocated()  # Current GPU memory\n",
        "torch.cuda.max_memory_allocated()  # Peak GPU memory\n",
        "\n",
        "# Python memory profiling\n",
        "tracemalloc.start()\n",
        "# ... your code ...\n",
        "current, peak = tracemalloc.get_traced_memory()\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.5 PyTorch/Tensor Operations\n",
        "\n",
        "### Tensor Memory Layout\n",
        "PyTorch tensors are stored in row-major (C-contiguous) order by default:\n",
        "```python\n",
        "import torch\n",
        "\n",
        "x = torch.randn(3, 4)\n",
        "print(x.is_contiguous())  # True\n",
        "print(x.stride())  # (4, 1) - elements in same row are adjacent\n",
        "```\n",
        "\n",
        "### Memory-Efficient Tensor Operations\n",
        "```python\n",
        "# Avoid creating intermediate tensors\n",
        "# Bad: Creates temporary tensors\n",
        "result = (x + y).sum().sqrt()\n",
        "\n",
        "# Good: Use in-place operations when possible\n",
        "result = x.add_(y).sum().sqrt_()\n",
        "\n",
        "# Or use functional operations\n",
        "result = torch.sqrt(torch.sum(torch.add(x, y)))\n",
        "```\n",
        "\n",
        "### Broadcasting and Memory\n",
        "Broadcasting can create large intermediate tensors:\n",
        "```python\n",
        "# This creates a (1000, 1000) tensor\n",
        "a = torch.randn(1000, 1)\n",
        "b = torch.randn(1, 1000)\n",
        "c = a + b  # Broadcasting creates large intermediate tensor\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Practice Questions\n",
        "\n",
        "Now let's apply these concepts with 5 progressive exercises. Each question builds on the previous concepts and increases in difficulty.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 1: Memory-Efficient Prefix Sum (Easy)\n",
        "\n",
        "**Problem**: Implement a memory-efficient prefix sum algorithm that computes the cumulative sum of an array in-place.\n",
        "\n",
        "**Requirements**:\n",
        "- Modify the input array in-place (O(1) extra space)\n",
        "- Time complexity: O(n)\n",
        "- Handle edge cases (empty array, single element)\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "arr = [1, 2, 3, 4, 5]\n",
        "prefix_sum_inplace(arr)\n",
        "print(arr)  # [1, 3, 6, 10, 15]\n",
        "```\n",
        "\n",
        "**Starter Code**:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prefix_sum_inplace(arr):\n",
        "    \"\"\"\n",
        "    Compute prefix sum in-place.\n",
        "    \n",
        "    Args:\n",
        "        arr: List of numbers to modify in-place\n",
        "        \n",
        "    Returns:\n",
        "        None (modifies input array)\n",
        "    \"\"\"\n",
        "    # TODO: Implement in-place prefix sum\n",
        "    pass\n",
        "\n",
        "# Comprehensive Test Suite\n",
        "def test_prefix_sum():\n",
        "    \"\"\"Comprehensive tests for prefix sum implementation.\"\"\"\n",
        "    print(\"Running comprehensive prefix sum tests...\")\n",
        "    \n",
        "    # Test case 1: Normal array\n",
        "    arr1 = [1, 2, 3, 4, 5]\n",
        "    original1 = arr1.copy()\n",
        "    prefix_sum_inplace(arr1)\n",
        "    expected1 = [1, 3, 6, 10, 15]\n",
        "    assert arr1 == expected1, f\"Test 1 failed: Expected {expected1}, got {arr1}\"\n",
        "    print(\"‚úì Test 1: Normal array passed\")\n",
        "    \n",
        "    # Test case 2: Single element\n",
        "    arr2 = [42]\n",
        "    original2 = arr2.copy()\n",
        "    prefix_sum_inplace(arr2)\n",
        "    expected2 = [42]\n",
        "    assert arr2 == expected2, f\"Test 2 failed: Expected {expected2}, got {arr2}\"\n",
        "    print(\"‚úì Test 2: Single element passed\")\n",
        "    \n",
        "    # Test case 3: Empty array\n",
        "    arr3 = []\n",
        "    original3 = arr3.copy()\n",
        "    prefix_sum_inplace(arr3)\n",
        "    expected3 = []\n",
        "    assert arr3 == expected3, f\"Test 3 failed: Expected {expected3}, got {arr3}\"\n",
        "    print(\"‚úì Test 3: Empty array passed\")\n",
        "    \n",
        "    # Test case 4: Negative numbers\n",
        "    arr4 = [-1, 2, -3, 4]\n",
        "    original4 = arr4.copy()\n",
        "    prefix_sum_inplace(arr4)\n",
        "    expected4 = [-1, 1, -2, 2]\n",
        "    assert arr4 == expected4, f\"Test 4 failed: Expected {expected4}, got {arr4}\"\n",
        "    print(\"‚úì Test 4: Negative numbers passed\")\n",
        "    \n",
        "    # Test case 5: All zeros\n",
        "    arr5 = [0, 0, 0, 0]\n",
        "    original5 = arr5.copy()\n",
        "    prefix_sum_inplace(arr5)\n",
        "    expected5 = [0, 0, 0, 0]\n",
        "    assert arr5 == expected5, f\"Test 5 failed: Expected {expected5}, got {arr5}\"\n",
        "    print(\"‚úì Test 5: All zeros passed\")\n",
        "    \n",
        "    # Test case 6: Large array\n",
        "    arr6 = list(range(1, 1001))  # [1, 2, 3, ..., 1000]\n",
        "    original6 = arr6.copy()\n",
        "    prefix_sum_inplace(arr6)\n",
        "    # Verify first few and last few elements\n",
        "    assert arr6[0] == 1, f\"Test 6 failed: First element should be 1, got {arr6[0]}\"\n",
        "    assert arr6[1] == 3, f\"Test 6 failed: Second element should be 3, got {arr6[1]}\"\n",
        "    assert arr6[2] == 6, f\"Test 6 failed: Third element should be 6, got {arr6[2]}\"\n",
        "    assert arr6[-1] == sum(range(1, 1001)), f\"Test 6 failed: Last element incorrect\"\n",
        "    print(\"‚úì Test 6: Large array passed\")\n",
        "    \n",
        "    # Test case 7: Mixed positive and negative\n",
        "    arr7 = [5, -3, 2, -1, 4]\n",
        "    original7 = arr7.copy()\n",
        "    prefix_sum_inplace(arr7)\n",
        "    expected7 = [5, 2, 4, 3, 7]\n",
        "    assert arr7 == expected7, f\"Test 7 failed: Expected {expected7}, got {arr7}\"\n",
        "    print(\"‚úì Test 7: Mixed positive/negative passed\")\n",
        "    \n",
        "    # Test case 8: Single negative number\n",
        "    arr8 = [-10]\n",
        "    original8 = arr8.copy()\n",
        "    prefix_sum_inplace(arr8)\n",
        "    expected8 = [-10]\n",
        "    assert arr8 == expected8, f\"Test 8 failed: Expected {expected8}, got {arr8}\"\n",
        "    print(\"‚úì Test 8: Single negative passed\")\n",
        "    \n",
        "    # Test case 9: Verify in-place modification\n",
        "    test_arr = [1, 2, 3]\n",
        "    original_ref = id(test_arr)\n",
        "    prefix_sum_inplace(test_arr)\n",
        "    assert id(test_arr) == original_ref, \"Test 9 failed: Array reference changed (not in-place)\"\n",
        "    print(\"‚úì Test 9: In-place modification verified\")\n",
        "    \n",
        "    # Test case 10: Edge case with very small numbers\n",
        "    arr10 = [0.1, 0.2, 0.3]\n",
        "    original10 = arr10.copy()\n",
        "    prefix_sum_inplace(arr10)\n",
        "    expected10 = [0.1, 0.3, 0.6]\n",
        "    assert all(abs(a - b) < 1e-10 for a, b in zip(arr10, expected10)), f\"Test 10 failed: Expected {expected10}, got {arr10}\"\n",
        "    print(\"‚úì Test 10: Small numbers passed\")\n",
        "    \n",
        "    print(\"\\nüéâ All 10 prefix sum tests passed!\")\n",
        "\n",
        "def test_prefix_sum_performance():\n",
        "    \"\"\"Performance test for prefix sum.\"\"\"\n",
        "    import time\n",
        "    \n",
        "    print(\"\\nRunning performance test...\")\n",
        "    \n",
        "    # Test with large array\n",
        "    sizes = [1000, 10000, 100000]\n",
        "    for size in sizes:\n",
        "        arr = list(range(1, size + 1))\n",
        "        \n",
        "        start_time = time.time()\n",
        "        prefix_sum_inplace(arr)\n",
        "        end_time = time.time()\n",
        "        \n",
        "        execution_time = end_time - start_time\n",
        "        print(f\"Size {size:,}: {execution_time:.6f} seconds\")\n",
        "        \n",
        "        # Verify correctness\n",
        "        expected_sum = sum(range(1, size + 1))\n",
        "        assert arr[-1] == expected_sum, f\"Performance test failed for size {size}\"\n",
        "    \n",
        "    print(\"‚úì Performance test passed!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_prefix_sum()\n",
        "    test_prefix_sum_performance()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 2: Tensor Operation Benchmarking (Easy-Medium)\n",
        "\n",
        "**Problem**: Compare the performance of Python loops vs NumPy vectorized operations for element-wise multiplication on large tensors.\n",
        "\n",
        "**Requirements**:\n",
        "- Implement both loop-based and vectorized versions\n",
        "- Measure execution time for different array sizes\n",
        "- Analyze memory usage patterns\n",
        "- Create a performance comparison plot\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Compare these approaches:\n",
        "# 1. Python loop: for i in range(n): result[i] = a[i] * b[i]\n",
        "# 2. NumPy vectorized: result = a * b\n",
        "```\n",
        "\n",
        "**Starter Code**:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import tracemalloc\n",
        "\n",
        "def elementwise_multiply_loop(a, b):\n",
        "    \"\"\"\n",
        "    Element-wise multiplication using Python loops.\n",
        "    \n",
        "    Args:\n",
        "        a, b: 1D numpy arrays of same length\n",
        "        \n",
        "    Returns:\n",
        "        numpy array: element-wise product\n",
        "    \"\"\"\n",
        "    # TODO: Implement using Python loops\n",
        "    pass\n",
        "\n",
        "def elementwise_multiply_vectorized(a, b):\n",
        "    \"\"\"\n",
        "    Element-wise multiplication using NumPy vectorization.\n",
        "    \n",
        "    Args:\n",
        "        a, b: 1D numpy arrays of same length\n",
        "        \n",
        "    Returns:\n",
        "        numpy array: element-wise product\n",
        "    \"\"\"\n",
        "    # TODO: Implement using NumPy vectorization\n",
        "    pass\n",
        "\n",
        "def benchmark_operations(sizes=[1000, 10000, 100000, 1000000]):\n",
        "    \"\"\"\n",
        "    Benchmark both approaches across different array sizes.\n",
        "    \n",
        "    Args:\n",
        "        sizes: List of array sizes to test\n",
        "        \n",
        "    Returns:\n",
        "        dict: Results with timing and memory usage\n",
        "    \"\"\"\n",
        "    # TODO: Implement benchmarking\n",
        "    pass\n",
        "\n",
        "def plot_performance(results):\n",
        "    \"\"\"\n",
        "    Create performance comparison plots.\n",
        "    \n",
        "    Args:\n",
        "        results: Dictionary with benchmark results\n",
        "    \"\"\"\n",
        "    # TODO: Create plots showing:\n",
        "    # 1. Execution time vs array size\n",
        "    # 2. Memory usage vs array size\n",
        "    # 3. Speedup ratio\n",
        "    pass\n",
        "\n",
        "# Comprehensive Test Suite\n",
        "def test_elementwise_operations():\n",
        "    \"\"\"Comprehensive tests for element-wise operations.\"\"\"\n",
        "    print(\"Running comprehensive element-wise operation tests...\")\n",
        "    \n",
        "    # Test case 1: Basic functionality\n",
        "    a1 = np.array([1, 2, 3, 4, 5])\n",
        "    b1 = np.array([2, 3, 4, 5, 6])\n",
        "    \n",
        "    result_loop1 = elementwise_multiply_loop(a1, b1)\n",
        "    result_vec1 = elementwise_multiply_vectorized(a1, b1)\n",
        "    expected1 = np.array([2, 6, 12, 20, 30])\n",
        "    \n",
        "    assert np.array_equal(result_loop1, expected1), f\"Loop test 1 failed: Expected {expected1}, got {result_loop1}\"\n",
        "    assert np.array_equal(result_vec1, expected1), f\"Vectorized test 1 failed: Expected {expected1}, got {result_vec1}\"\n",
        "    assert np.array_equal(result_loop1, result_vec1), \"Loop and vectorized results don't match!\"\n",
        "    print(\"‚úì Test 1: Basic functionality passed\")\n",
        "    \n",
        "    # Test case 2: Negative numbers\n",
        "    a2 = np.array([-1, -2, -3])\n",
        "    b2 = np.array([2, -2, 3])\n",
        "    \n",
        "    result_loop2 = elementwise_multiply_loop(a2, b2)\n",
        "    result_vec2 = elementwise_multiply_vectorized(a2, b2)\n",
        "    expected2 = np.array([-2, 4, -9])\n",
        "    \n",
        "    assert np.array_equal(result_loop2, expected2), f\"Loop test 2 failed: Expected {expected2}, got {result_loop2}\"\n",
        "    assert np.array_equal(result_vec2, expected2), f\"Vectorized test 2 failed: Expected {expected2}, got {result_vec2}\"\n",
        "    print(\"‚úì Test 2: Negative numbers passed\")\n",
        "    \n",
        "    # Test case 3: Single element\n",
        "    a3 = np.array([42])\n",
        "    b3 = np.array([2])\n",
        "    \n",
        "    result_loop3 = elementwise_multiply_loop(a3, b3)\n",
        "    result_vec3 = elementwise_multiply_vectorized(a3, b3)\n",
        "    expected3 = np.array([84])\n",
        "    \n",
        "    assert np.array_equal(result_loop3, expected3), f\"Loop test 3 failed: Expected {expected3}, got {result_loop3}\"\n",
        "    assert np.array_equal(result_vec3, expected3), f\"Vectorized test 3 failed: Expected {expected3}, got {result_vec3}\"\n",
        "    print(\"‚úì Test 3: Single element passed\")\n",
        "    \n",
        "    # Test case 4: Empty arrays\n",
        "    a4 = np.array([])\n",
        "    b4 = np.array([])\n",
        "    \n",
        "    result_loop4 = elementwise_multiply_loop(a4, b4)\n",
        "    result_vec4 = elementwise_multiply_vectorized(a4, b4)\n",
        "    expected4 = np.array([])\n",
        "    \n",
        "    assert np.array_equal(result_loop4, expected4), f\"Loop test 4 failed: Expected {expected4}, got {result_loop4}\"\n",
        "    assert np.array_equal(result_vec4, expected4), f\"Vectorized test 4 failed: Expected {expected4}, got {result_vec4}\"\n",
        "    print(\"‚úì Test 4: Empty arrays passed\")\n",
        "    \n",
        "    # Test case 5: Floating point precision\n",
        "    a5 = np.array([0.1, 0.2, 0.3])\n",
        "    b5 = np.array([2.0, 3.0, 4.0])\n",
        "    \n",
        "    result_loop5 = elementwise_multiply_loop(a5, b5)\n",
        "    result_vec5 = elementwise_multiply_vectorized(a5, b5)\n",
        "    expected5 = np.array([0.2, 0.6, 1.2])\n",
        "    \n",
        "    assert np.allclose(result_loop5, expected5, rtol=1e-10), f\"Loop test 5 failed: Expected {expected5}, got {result_loop5}\"\n",
        "    assert np.allclose(result_vec5, expected5, rtol=1e-10), f\"Vectorized test 5 failed: Expected {expected5}, got {result_vec5}\"\n",
        "    print(\"‚úì Test 5: Floating point precision passed\")\n",
        "    \n",
        "    # Test case 6: Large arrays\n",
        "    size = 10000\n",
        "    a6 = np.random.randn(size)\n",
        "    b6 = np.random.randn(size)\n",
        "    \n",
        "    result_loop6 = elementwise_multiply_loop(a6, b6)\n",
        "    result_vec6 = elementwise_multiply_vectorized(a6, b6)\n",
        "    \n",
        "    assert np.allclose(result_loop6, result_vec6, rtol=1e-10), \"Large array test failed: Results don't match!\"\n",
        "    print(\"‚úì Test 6: Large arrays passed\")\n",
        "    \n",
        "    # Test case 7: Different shapes (should raise error)\n",
        "    try:\n",
        "        a7 = np.array([1, 2, 3])\n",
        "        b7 = np.array([1, 2])  # Different length\n",
        "        elementwise_multiply_loop(a7, b7)\n",
        "        assert False, \"Should have raised an error for different shapes\"\n",
        "    except (ValueError, IndexError):\n",
        "        print(\"‚úì Test 7: Shape validation passed\")\n",
        "    \n",
        "    print(\"\\nüéâ All 7 element-wise operation tests passed!\")\n",
        "\n",
        "def test_benchmarking():\n",
        "    \"\"\"Test the benchmarking functionality.\"\"\"\n",
        "    print(\"\\nRunning benchmarking tests...\")\n",
        "    \n",
        "    # Test with small sizes first\n",
        "    results = benchmark_operations(sizes=[100, 1000])\n",
        "    \n",
        "    # Verify results structure\n",
        "    assert 'sizes' in results, \"Results should contain 'sizes'\"\n",
        "    assert 'loop_times' in results, \"Results should contain 'loop_times'\"\n",
        "    assert 'vectorized_times' in results, \"Results should contain 'vectorized_times'\"\n",
        "    assert 'memory_loop' in results, \"Results should contain 'memory_loop'\"\n",
        "    assert 'memory_vectorized' in results, \"Results should contain 'memory_vectorized'\"\n",
        "    \n",
        "    # Verify vectorized is faster\n",
        "    for size in results['sizes']:\n",
        "        loop_time = results['loop_times'][size]\n",
        "        vec_time = results['vectorized_times'][size]\n",
        "        assert vec_time < loop_time, f\"Vectorized should be faster for size {size}\"\n",
        "    \n",
        "    print(\"‚úì Benchmarking tests passed!\")\n",
        "\n",
        "def test_performance_analysis():\n",
        "    \"\"\"Test performance analysis and plotting.\"\"\"\n",
        "    print(\"\\nRunning performance analysis tests...\")\n",
        "    \n",
        "    # Test with small dataset\n",
        "    results = benchmark_operations(sizes=[100, 500, 1000])\n",
        "    \n",
        "    # Test plotting (should not crash)\n",
        "    try:\n",
        "        plot_performance(results)\n",
        "        print(\"‚úì Plotting functionality works\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  Plotting test failed: {e}\")\n",
        "    \n",
        "    # Verify performance trends\n",
        "    sizes = results['sizes']\n",
        "    loop_times = [results['loop_times'][s] for s in sizes]\n",
        "    vec_times = [results['vectorized_times'][s] for s in sizes]\n",
        "    \n",
        "    # Vectorized should be consistently faster\n",
        "    for i in range(len(sizes)):\n",
        "        assert vec_times[i] < loop_times[i], f\"Vectorized not faster for size {sizes[i]}\"\n",
        "    \n",
        "    print(\"‚úì Performance analysis tests passed!\")\n",
        "\n",
        "# Test the implementations\n",
        "if __name__ == \"__main__\":\n",
        "    test_elementwise_operations()\n",
        "    test_benchmarking()\n",
        "    test_performance_analysis()\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"Running full benchmark with visualization...\")\n",
        "    results = benchmark_operations()\n",
        "    plot_performance(results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 3: Cache-Aware Matrix Operations (Medium)\n",
        "\n",
        "**Problem**: Implement matrix multiplication with cache-aware optimization. Compare different memory access patterns and their impact on performance.\n",
        "\n",
        "**Requirements**:\n",
        "- Implement standard matrix multiplication\n",
        "- Implement cache-optimized version (tiling/blocking)\n",
        "- Measure performance difference\n",
        "- Analyze cache miss rates\n",
        "\n",
        "**Background**: Matrix multiplication C = A √ó B where A is m√ók, B is k√ón, C is m√ón.\n",
        "The standard algorithm has poor cache locality when matrices don't fit in cache.\n",
        "\n",
        "**Starter Code**:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "from numba import jit\n",
        "\n",
        "def matrix_multiply_naive(A, B):\n",
        "    \"\"\"\n",
        "    Standard matrix multiplication with poor cache locality.\n",
        "    \n",
        "    Args:\n",
        "        A: numpy array of shape (m, k)\n",
        "        B: numpy array of shape (k, n)\n",
        "        \n",
        "    Returns:\n",
        "        numpy array of shape (m, n)\n",
        "    \"\"\"\n",
        "    m, k = A.shape\n",
        "    k2, n = B.shape\n",
        "    assert k == k2, \"Inner dimensions must match\"\n",
        "    \n",
        "    # TODO: Implement standard matrix multiplication\n",
        "    pass\n",
        "\n",
        "def matrix_multiply_tiled(A, B, tile_size=64):\n",
        "    \"\"\"\n",
        "    Cache-optimized matrix multiplication using tiling.\n",
        "    \n",
        "    Args:\n",
        "        A: numpy array of shape (m, k)\n",
        "        B: numpy array of shape (k, n)\n",
        "        tile_size: Size of the tile for blocking\n",
        "        \n",
        "    Returns:\n",
        "        numpy array of shape (m, n)\n",
        "    \"\"\"\n",
        "    m, k = A.shape\n",
        "    k2, n = B.shape\n",
        "    assert k == k2, \"Inner dimensions must match\"\n",
        "    \n",
        "    # TODO: Implement tiled matrix multiplication\n",
        "    pass\n",
        "\n",
        "@jit(nopython=True)\n",
        "def matrix_multiply_numba(A, B):\n",
        "    \"\"\"\n",
        "    Numba-optimized matrix multiplication for comparison.\n",
        "    \n",
        "    Args:\n",
        "        A: numpy array of shape (m, k)\n",
        "        B: numpy array of shape (k, n)\n",
        "        \n",
        "    Returns:\n",
        "        numpy array of shape (m, n)\n",
        "    \"\"\"\n",
        "    # TODO: Implement with Numba JIT compilation\n",
        "    pass\n",
        "\n",
        "def benchmark_matrix_multiply(sizes=[64, 128, 256, 512, 1024]):\n",
        "    \"\"\"\n",
        "    Benchmark different matrix multiplication approaches.\n",
        "    \n",
        "    Args:\n",
        "        sizes: List of matrix sizes to test (square matrices)\n",
        "        \n",
        "    Returns:\n",
        "        dict: Performance results\n",
        "    \"\"\"\n",
        "    # TODO: Implement benchmarking\n",
        "    pass\n",
        "\n",
        "def verify_correctness():\n",
        "    \"\"\"Verify all implementations produce the same result.\"\"\"\n",
        "    # TODO: Test with small matrices to ensure correctness\n",
        "    pass\n",
        "\n",
        "# Comprehensive Test Suite\n",
        "def test_matrix_multiply_correctness():\n",
        "    \"\"\"Comprehensive correctness tests for matrix multiplication.\"\"\"\n",
        "    print(\"Running comprehensive matrix multiplication correctness tests...\")\n",
        "    \n",
        "    # Test case 1: Small matrices\n",
        "    A1 = np.array([[1, 2], [3, 4]], dtype=np.float32)\n",
        "    B1 = np.array([[5, 6], [7, 8]], dtype=np.float32)\n",
        "    expected1 = np.array([[19, 22], [43, 50]], dtype=np.float32)\n",
        "    \n",
        "    result_naive1 = matrix_multiply_naive(A1, B1)\n",
        "    result_tiled1 = matrix_multiply_tiled(A1, B1)\n",
        "    result_numba1 = matrix_multiply_numba(A1, B1)\n",
        "    \n",
        "    assert np.allclose(result_naive1, expected1, rtol=1e-6), f\"Naive test 1 failed: Expected {expected1}, got {result_naive1}\"\n",
        "    assert np.allclose(result_tiled1, expected1, rtol=1e-6), f\"Tiled test 1 failed: Expected {expected1}, got {result_tiled1}\"\n",
        "    assert np.allclose(result_numba1, expected1, rtol=1e-6), f\"Numba test 1 failed: Expected {expected1}, got {result_numba1}\"\n",
        "    print(\"‚úì Test 1: Small matrices passed\")\n",
        "    \n",
        "    # Test case 2: Identity matrix\n",
        "    I = np.eye(3, dtype=np.float32)\n",
        "    A2 = np.random.randn(3, 3).astype(np.float32)\n",
        "    \n",
        "    result_naive2 = matrix_multiply_naive(A2, I)\n",
        "    result_tiled2 = matrix_multiply_tiled(A2, I)\n",
        "    result_numba2 = matrix_multiply_numba(A2, I)\n",
        "    \n",
        "    assert np.allclose(result_naive2, A2, rtol=1e-6), \"Naive identity test failed\"\n",
        "    assert np.allclose(result_tiled2, A2, rtol=1e-6), \"Tiled identity test failed\"\n",
        "    assert np.allclose(result_numba2, A2, rtol=1e-6), \"Numba identity test failed\"\n",
        "    print(\"‚úì Test 2: Identity matrix passed\")\n",
        "    \n",
        "    # Test case 3: Zero matrix\n",
        "    A3 = np.zeros((2, 3), dtype=np.float32)\n",
        "    B3 = np.random.randn(3, 4).astype(np.float32)\n",
        "    expected3 = np.zeros((2, 4), dtype=np.float32)\n",
        "    \n",
        "    result_naive3 = matrix_multiply_naive(A3, B3)\n",
        "    result_tiled3 = matrix_multiply_tiled(A3, B3)\n",
        "    result_numba3 = matrix_multiply_numba(A3, B3)\n",
        "    \n",
        "    assert np.allclose(result_naive3, expected3, rtol=1e-6), \"Naive zero test failed\"\n",
        "    assert np.allclose(result_tiled3, expected3, rtol=1e-6), \"Tiled zero test failed\"\n",
        "    assert np.allclose(result_numba3, expected3, rtol=1e-6), \"Numba zero test failed\"\n",
        "    print(\"‚úì Test 3: Zero matrix passed\")\n",
        "    \n",
        "    # Test case 4: Non-square matrices\n",
        "    A4 = np.random.randn(2, 3).astype(np.float32)\n",
        "    B4 = np.random.randn(3, 4).astype(np.float32)\n",
        "    \n",
        "    result_naive4 = matrix_multiply_naive(A4, B4)\n",
        "    result_tiled4 = matrix_multiply_tiled(A4, B4)\n",
        "    result_numba4 = matrix_multiply_numba(A4, B4)\n",
        "    \n",
        "    # All should produce same result\n",
        "    assert np.allclose(result_naive4, result_tiled4, rtol=1e-6), \"Non-square naive vs tiled failed\"\n",
        "    assert np.allclose(result_naive4, result_numba4, rtol=1e-6), \"Non-square naive vs numba failed\"\n",
        "    assert result_naive4.shape == (2, 4), f\"Wrong output shape: {result_naive4.shape}\"\n",
        "    print(\"‚úì Test 4: Non-square matrices passed\")\n",
        "    \n",
        "    # Test case 5: Single element\n",
        "    A5 = np.array([[5]], dtype=np.float32)\n",
        "    B5 = np.array([[3]], dtype=np.float32)\n",
        "    expected5 = np.array([[15]], dtype=np.float32)\n",
        "    \n",
        "    result_naive5 = matrix_multiply_naive(A5, B5)\n",
        "    result_tiled5 = matrix_multiply_tiled(A5, B5)\n",
        "    result_numba5 = matrix_multiply_numba(A5, B5)\n",
        "    \n",
        "    assert np.allclose(result_naive5, expected5, rtol=1e-6), \"Naive single element test failed\"\n",
        "    assert np.allclose(result_tiled5, expected5, rtol=1e-6), \"Tiled single element test failed\"\n",
        "    assert np.allclose(result_numba5, expected5, rtol=1e-6), \"Numba single element test failed\"\n",
        "    print(\"‚úì Test 5: Single element passed\")\n",
        "    \n",
        "    # Test case 6: Dimension mismatch (should raise error)\n",
        "    try:\n",
        "        A6 = np.random.randn(2, 3)\n",
        "        B6 = np.random.randn(4, 5)  # Wrong inner dimension\n",
        "        matrix_multiply_naive(A6, B6)\n",
        "        assert False, \"Should have raised an error for dimension mismatch\"\n",
        "    except AssertionError:\n",
        "        print(\"‚úì Test 6: Dimension validation passed\")\n",
        "    \n",
        "    print(\"\\nüéâ All 6 matrix multiplication correctness tests passed!\")\n",
        "\n",
        "def test_matrix_multiply_performance():\n",
        "    \"\"\"Test matrix multiplication performance.\"\"\"\n",
        "    print(\"\\nRunning matrix multiplication performance tests...\")\n",
        "    \n",
        "    # Test with different sizes\n",
        "    sizes = [16, 32, 64, 128]\n",
        "    results = benchmark_matrix_multiply(sizes)\n",
        "    \n",
        "    # Verify results structure\n",
        "    assert 'sizes' in results, \"Results should contain 'sizes'\"\n",
        "    assert 'naive_times' in results, \"Results should contain 'naive_times'\"\n",
        "    assert 'tiled_times' in results, \"Results should contain 'tiled_times'\"\n",
        "    assert 'numba_times' in results, \"Results should contain 'numba_times'\"\n",
        "    \n",
        "    # Verify all methods work\n",
        "    for size in sizes:\n",
        "        assert size in results['naive_times'], f\"Missing naive time for size {size}\"\n",
        "        assert size in results['tiled_times'], f\"Missing tiled time for size {size}\"\n",
        "        assert size in results['numba_times'], f\"Missing numba time for size {size}\"\n",
        "        \n",
        "        # Times should be positive\n",
        "        assert results['naive_times'][size] > 0, f\"Invalid naive time for size {size}\"\n",
        "        assert results['tiled_times'][size] > 0, f\"Invalid tiled time for size {size}\"\n",
        "        assert results['numba_times'][size] > 0, f\"Invalid numba time for size {size}\"\n",
        "    \n",
        "    print(\"‚úì Performance tests passed!\")\n",
        "\n",
        "def test_tiling_effectiveness():\n",
        "    \"\"\"Test that tiling is effective for larger matrices.\"\"\"\n",
        "    print(\"\\nRunning tiling effectiveness tests...\")\n",
        "    \n",
        "    # Test with larger matrices where tiling should help\n",
        "    large_sizes = [256, 512]\n",
        "    results = benchmark_matrix_multiply(large_sizes)\n",
        "    \n",
        "    for size in large_sizes:\n",
        "        naive_time = results['naive_times'][size]\n",
        "        tiled_time = results['tiled_times'][size]\n",
        "        \n",
        "        # Tiled should be faster or at least not significantly slower\n",
        "        if tiled_time < naive_time:\n",
        "            speedup = naive_time / tiled_time\n",
        "            print(f\"‚úì Size {size}: Tiled is {speedup:.2f}x faster\")\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è  Size {size}: Tiled is slower (may need tuning)\")\n",
        "    \n",
        "    print(\"‚úì Tiling effectiveness tests completed!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Run all tests\n",
        "    test_matrix_multiply_correctness()\n",
        "    test_matrix_multiply_performance()\n",
        "    test_tiling_effectiveness()\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"Running full benchmark with visualization...\")\n",
        "    results = benchmark_matrix_multiply()\n",
        "    \n",
        "    # Print results\n",
        "    for size in results['sizes']:\n",
        "        print(f\"Size {size}x{size}:\")\n",
        "        print(f\"  Naive: {results['naive_times'][size]:.4f}s\")\n",
        "        print(f\"  Tiled: {results['tiled_times'][size]:.4f}s\")\n",
        "        print(f\"  Numba: {results['numba_times'][size]:.4f}s\")\n",
        "        print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 4: Custom Sparse Tensor Operations (Medium-Hard)\n",
        "\n",
        "**Problem**: Implement a memory-efficient sparse tensor class with basic operations like addition, multiplication, and reshaping.\n",
        "\n",
        "**Requirements**:\n",
        "- Use COO (Coordinate) format for sparse representation\n",
        "- Implement tensor addition and element-wise multiplication\n",
        "- Support reshaping operations\n",
        "- Memory usage should be O(nnz) where nnz is number of non-zeros\n",
        "- Compare with dense tensor operations\n",
        "\n",
        "**Background**: Sparse tensors store only non-zero values, making them memory-efficient for data with many zeros.\n",
        "\n",
        "**Starter Code**:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from typing import List, Tuple, Union\n",
        "\n",
        "class SparseTensor:\n",
        "    \"\"\"\n",
        "    Memory-efficient sparse tensor using COO (Coordinate) format.\n",
        "    \n",
        "    Stores only non-zero values with their coordinates.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, shape: Tuple[int, ...], values: np.ndarray = None, \n",
        "                 indices: np.ndarray = None):\n",
        "        \"\"\"\n",
        "        Initialize sparse tensor.\n",
        "        \n",
        "        Args:\n",
        "            shape: Tensor dimensions\n",
        "            values: Non-zero values (1D array)\n",
        "            indices: Coordinates of non-zero values (2D array, shape: [nnz, ndim])\n",
        "        \"\"\"\n",
        "        self.shape = shape\n",
        "        self.ndim = len(shape)\n",
        "        \n",
        "        if values is None:\n",
        "            self.values = np.array([], dtype=np.float32)\n",
        "            self.indices = np.array([], dtype=np.int32).reshape(0, self.ndim)\n",
        "        else:\n",
        "            self.values = values.astype(np.float32)\n",
        "            self.indices = indices.astype(np.int32)\n",
        "            self._validate()\n",
        "    \n",
        "    def _validate(self):\n",
        "        \"\"\"Validate tensor data.\"\"\"\n",
        "        # TODO: Add validation checks\n",
        "        pass\n",
        "    \n",
        "    def to_dense(self) -> np.ndarray:\n",
        "        \"\"\"Convert to dense tensor.\"\"\"\n",
        "        # TODO: Implement conversion to dense\n",
        "        pass\n",
        "    \n",
        "    @classmethod\n",
        "    def from_dense(cls, dense_tensor: np.ndarray) -> 'SparseTensor':\n",
        "        \"\"\"Create sparse tensor from dense tensor.\"\"\"\n",
        "        # TODO: Implement conversion from dense\n",
        "        pass\n",
        "    \n",
        "    def add(self, other: 'SparseTensor') -> 'SparseTensor':\n",
        "        \"\"\"Add two sparse tensors.\"\"\"\n",
        "        # TODO: Implement sparse tensor addition\n",
        "        pass\n",
        "    \n",
        "    def multiply_elementwise(self, other: 'SparseTensor') -> 'SparseTensor':\n",
        "        \"\"\"Element-wise multiplication of two sparse tensors.\"\"\"\n",
        "        # TODO: Implement element-wise multiplication\n",
        "        pass\n",
        "    \n",
        "    def reshape(self, new_shape: Tuple[int, ...]) -> 'SparseTensor':\n",
        "        \"\"\"Reshape the tensor.\"\"\"\n",
        "        # TODO: Implement reshaping\n",
        "        pass\n",
        "    \n",
        "    def memory_usage(self) -> int:\n",
        "        \"\"\"Calculate memory usage in bytes.\"\"\"\n",
        "        # TODO: Calculate actual memory usage\n",
        "        pass\n",
        "    \n",
        "    def sparsity(self) -> float:\n",
        "        \"\"\"Calculate sparsity ratio (fraction of zeros).\"\"\"\n",
        "        # TODO: Calculate sparsity\n",
        "        pass\n",
        "\n",
        "def create_sparse_tensor(shape: Tuple[int, ...], sparsity: float = 0.9) -> SparseTensor:\n",
        "    \"\"\"\n",
        "    Create a random sparse tensor with given sparsity.\n",
        "    \n",
        "    Args:\n",
        "        shape: Tensor dimensions\n",
        "        sparsity: Fraction of elements that should be zero\n",
        "        \n",
        "    Returns:\n",
        "        SparseTensor: Random sparse tensor\n",
        "    \"\"\"\n",
        "    # TODO: Implement random sparse tensor creation\n",
        "    pass\n",
        "\n",
        "def benchmark_sparse_vs_dense(shape: Tuple[int, ...], sparsity: float = 0.9):\n",
        "    \"\"\"\n",
        "    Benchmark sparse vs dense operations.\n",
        "    \n",
        "    Args:\n",
        "        shape: Tensor dimensions\n",
        "        sparsity: Sparsity level\n",
        "        \n",
        "    Returns:\n",
        "        dict: Performance comparison\n",
        "    \"\"\"\n",
        "    # TODO: Implement benchmarking\n",
        "    pass\n",
        "\n",
        "# Comprehensive Test Suite\n",
        "def test_sparse_tensor_basic():\n",
        "    \"\"\"Test basic sparse tensor functionality.\"\"\"\n",
        "    print(\"Running basic sparse tensor tests...\")\n",
        "    \n",
        "    # Test case 1: Empty tensor\n",
        "    empty_tensor = SparseTensor((0, 0))\n",
        "    assert empty_tensor.shape == (0, 0)\n",
        "    assert empty_tensor.ndim == 2\n",
        "    assert empty_tensor.sparsity() == 1.0  # All zeros\n",
        "    print(\"‚úì Test 1: Empty tensor passed\")\n",
        "    \n",
        "    # Test case 2: Single element tensor\n",
        "    values = np.array([5.0])\n",
        "    indices = np.array([[0, 0]])\n",
        "    single_tensor = SparseTensor((1, 1), values, indices)\n",
        "    \n",
        "    assert single_tensor.shape == (1, 1)\n",
        "    assert single_tensor.sparsity() == 0.0  # No zeros\n",
        "    dense = single_tensor.to_dense()\n",
        "    assert dense.shape == (1, 1)\n",
        "    assert dense[0, 0] == 5.0\n",
        "    print(\"‚úì Test 2: Single element tensor passed\")\n",
        "    \n",
        "    # Test case 3: Small 2D tensor\n",
        "    values = np.array([1.0, 2.0, 3.0])\n",
        "    indices = np.array([[0, 0], [1, 1], [2, 2]])\n",
        "    diag_tensor = SparseTensor((3, 3), values, indices)\n",
        "    \n",
        "    assert diag_tensor.shape == (3, 3)\n",
        "    assert diag_tensor.sparsity() == 2/3  # 6 zeros out of 9 elements\n",
        "    dense = diag_tensor.to_dense()\n",
        "    expected = np.array([[1, 0, 0], [0, 2, 0], [0, 0, 3]])\n",
        "    assert np.array_equal(dense, expected)\n",
        "    print(\"‚úì Test 3: Small 2D tensor passed\")\n",
        "    \n",
        "    print(\"üéâ Basic sparse tensor tests passed!\")\n",
        "\n",
        "def test_sparse_tensor_operations():\n",
        "    \"\"\"Test sparse tensor operations.\"\"\"\n",
        "    print(\"\\nRunning sparse tensor operations tests...\")\n",
        "    \n",
        "    # Test case 1: Addition\n",
        "    values1 = np.array([1.0, 2.0])\n",
        "    indices1 = np.array([[0, 0], [1, 1]])\n",
        "    tensor1 = SparseTensor((2, 2), values1, indices1)\n",
        "    \n",
        "    values2 = np.array([3.0, 4.0])\n",
        "    indices2 = np.array([[0, 0], [1, 1]])\n",
        "    tensor2 = SparseTensor((2, 2), values2, indices2)\n",
        "    \n",
        "    result = tensor1.add(tensor2)\n",
        "    expected_dense = np.array([[4, 0], [0, 6]])\n",
        "    assert np.array_equal(result.to_dense(), expected_dense)\n",
        "    print(\"‚úì Test 1: Addition passed\")\n",
        "    \n",
        "    # Test case 2: Element-wise multiplication\n",
        "    result_mult = tensor1.multiply_elementwise(tensor2)\n",
        "    expected_mult = np.array([[3, 0], [0, 8]])\n",
        "    assert np.array_equal(result_mult.to_dense(), expected_mult)\n",
        "    print(\"‚úì Test 2: Element-wise multiplication passed\")\n",
        "    \n",
        "    # Test case 3: Reshaping\n",
        "    values3 = np.array([1.0, 2.0, 3.0, 4.0])\n",
        "    indices3 = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "    tensor3 = SparseTensor((2, 2), values3, indices3)\n",
        "    \n",
        "    reshaped = tensor3.reshape((4, 1))\n",
        "    assert reshaped.shape == (4, 1)\n",
        "    # Verify values are preserved\n",
        "    assert len(reshaped.values) == 4\n",
        "    print(\"‚úì Test 3: Reshaping passed\")\n",
        "    \n",
        "    print(\"üéâ Sparse tensor operations tests passed!\")\n",
        "\n",
        "def test_sparse_tensor_from_dense():\n",
        "    \"\"\"Test conversion from dense to sparse.\"\"\"\n",
        "    print(\"\\nRunning dense to sparse conversion tests...\")\n",
        "    \n",
        "    # Test case 1: Dense matrix with zeros\n",
        "    dense1 = np.array([[1, 0, 3], [0, 5, 0], [7, 0, 9]])\n",
        "    sparse1 = SparseTensor.from_dense(dense1)\n",
        "    \n",
        "    assert sparse1.shape == (3, 3)\n",
        "    assert sparse1.sparsity() == 4/9  # 4 zeros out of 9\n",
        "    assert np.array_equal(sparse1.to_dense(), dense1)\n",
        "    print(\"‚úì Test 1: Dense to sparse conversion passed\")\n",
        "    \n",
        "    # Test case 2: All zeros\n",
        "    dense2 = np.zeros((2, 3))\n",
        "    sparse2 = SparseTensor.from_dense(dense2)\n",
        "    \n",
        "    assert sparse2.sparsity() == 1.0  # All zeros\n",
        "    assert len(sparse2.values) == 0  # No non-zero values\n",
        "    print(\"‚úì Test 2: All zeros matrix passed\")\n",
        "    \n",
        "    # Test case 3: No zeros\n",
        "    dense3 = np.array([[1, 2], [3, 4]])\n",
        "    sparse3 = SparseTensor.from_dense(dense3)\n",
        "    \n",
        "    assert sparse3.sparsity() == 0.0  # No zeros\n",
        "    assert len(sparse3.values) == 4  # All values are non-zero\n",
        "    print(\"‚úì Test 3: No zeros matrix passed\")\n",
        "    \n",
        "    print(\"üéâ Dense to sparse conversion tests passed!\")\n",
        "\n",
        "def test_sparse_tensor_memory():\n",
        "    \"\"\"Test memory usage calculations.\"\"\"\n",
        "    print(\"\\nRunning memory usage tests...\")\n",
        "    \n",
        "    # Test case 1: Memory usage calculation\n",
        "    values = np.array([1.0, 2.0, 3.0], dtype=np.float32)\n",
        "    indices = np.array([[0, 0], [1, 1], [2, 2]], dtype=np.int32)\n",
        "    tensor = SparseTensor((3, 3), values, indices)\n",
        "    \n",
        "    memory = tensor.memory_usage()\n",
        "    assert memory > 0, \"Memory usage should be positive\"\n",
        "    \n",
        "    # Should be much less than dense equivalent\n",
        "    dense_memory = 3 * 3 * 4  # 3x3 float32 = 36 bytes\n",
        "    assert memory < dense_memory, \"Sparse should use less memory than dense\"\n",
        "    print(\"‚úì Test 1: Memory usage calculation passed\")\n",
        "    \n",
        "    # Test case 2: Memory vs sparsity relationship\n",
        "    # More sparse should use less memory\n",
        "    sparse_tensor = create_sparse_tensor((100, 100), sparsity=0.9)\n",
        "    dense_tensor = create_sparse_tensor((100, 100), sparsity=0.0)\n",
        "    \n",
        "    sparse_memory = sparse_tensor.memory_usage()\n",
        "    dense_memory = dense_tensor.memory_usage()\n",
        "    \n",
        "    assert sparse_memory < dense_memory, \"Sparser tensor should use less memory\"\n",
        "    print(\"‚úì Test 2: Memory vs sparsity relationship passed\")\n",
        "    \n",
        "    print(\"üéâ Memory usage tests passed!\")\n",
        "\n",
        "def test_sparse_tensor_edge_cases():\n",
        "    \"\"\"Test edge cases and error handling.\"\"\"\n",
        "    print(\"\\nRunning edge cases tests...\")\n",
        "    \n",
        "    # Test case 1: Invalid shape\n",
        "    try:\n",
        "        SparseTensor((0, 0), np.array([1.0]), np.array([[0, 0]]))\n",
        "        assert False, \"Should raise error for invalid shape\"\n",
        "    except (ValueError, AssertionError):\n",
        "        print(\"‚úì Test 1: Invalid shape validation passed\")\n",
        "    \n",
        "    # Test case 2: Mismatched values and indices\n",
        "    try:\n",
        "        values = np.array([1.0, 2.0])\n",
        "        indices = np.array([[0, 0]])  # Only one index for two values\n",
        "        SparseTensor((2, 2), values, indices)\n",
        "        assert False, \"Should raise error for mismatched dimensions\"\n",
        "    except (ValueError, AssertionError):\n",
        "        print(\"‚úì Test 2: Mismatched dimensions validation passed\")\n",
        "    \n",
        "    # Test case 3: Invalid indices\n",
        "    try:\n",
        "        values = np.array([1.0])\n",
        "        indices = np.array([[5, 5]])  # Index out of bounds for (2, 2) tensor\n",
        "        SparseTensor((2, 2), values, indices)\n",
        "        assert False, \"Should raise error for out-of-bounds indices\"\n",
        "    except (ValueError, AssertionError):\n",
        "        print(\"‚úì Test 3: Out-of-bounds indices validation passed\")\n",
        "    \n",
        "    print(\"üéâ Edge cases tests passed!\")\n",
        "\n",
        "def test_benchmarking():\n",
        "    \"\"\"Test benchmarking functionality.\"\"\"\n",
        "    print(\"\\nRunning benchmarking tests...\")\n",
        "    \n",
        "    # Test with small tensors\n",
        "    results = benchmark_sparse_vs_dense((10, 10), sparsity=0.5)\n",
        "    \n",
        "    # Verify results structure\n",
        "    assert 'sparse_memory' in results\n",
        "    assert 'dense_memory' in results\n",
        "    assert 'memory_savings' in results\n",
        "    \n",
        "    # Verify memory savings calculation\n",
        "    expected_savings = (results['dense_memory'] - results['sparse_memory']) / results['dense_memory']\n",
        "    assert abs(results['memory_savings'] - expected_savings) < 1e-6\n",
        "    \n",
        "    print(\"‚úì Benchmarking tests passed!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Run all tests\n",
        "    test_sparse_tensor_basic()\n",
        "    test_sparse_tensor_operations()\n",
        "    test_sparse_tensor_from_dense()\n",
        "    test_sparse_tensor_memory()\n",
        "    test_sparse_tensor_edge_cases()\n",
        "    test_benchmarking()\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"Running benchmark example...\")\n",
        "    \n",
        "    # Benchmark example\n",
        "    results = benchmark_sparse_vs_dense((100, 100), sparsity=0.95)\n",
        "    print(f\"Sparse memory: {results['sparse_memory']} bytes\")\n",
        "    print(f\"Dense memory: {results['dense_memory']} bytes\")\n",
        "    print(f\"Memory savings: {results['memory_savings']:.1%}\")\n",
        "    \n",
        "    print(\"\\nüéâ All sparse tensor tests completed successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 5: Memory Profiling and Optimization (Hard)\n",
        "\n",
        "**Problem**: Implement a comprehensive memory profiler for PyTorch operations and optimize a memory-intensive neural network forward pass.\n",
        "\n",
        "**Requirements**:\n",
        "- Create a memory profiler that tracks GPU/CPU memory usage\n",
        "- Profile a multi-layer neural network forward pass\n",
        "- Identify memory bottlenecks and optimize them\n",
        "- Implement gradient checkpointing to reduce memory usage\n",
        "- Compare memory usage before and after optimization\n",
        "\n",
        "**Background**: Large neural networks can consume massive amounts of memory. Understanding and optimizing memory usage is crucial for training large models.\n",
        "\n",
        "**Starter Code**:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "import psutil\n",
        "import gc\n",
        "from contextlib import contextmanager\n",
        "from typing import Dict, List, Optional\n",
        "\n",
        "class MemoryProfiler:\n",
        "    \"\"\"\n",
        "    Memory profiler for PyTorch operations.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, device: str = 'cuda' if torch.cuda.is_available() else 'cpu'):\n",
        "        self.device = device\n",
        "        self.memory_log = []\n",
        "        self.peak_memory = 0\n",
        "        \n",
        "    def get_memory_usage(self) -> Dict[str, float]:\n",
        "        \"\"\"Get current memory usage in MB.\"\"\"\n",
        "        # TODO: Implement memory usage tracking\n",
        "        pass\n",
        "    \n",
        "    def log_memory(self, operation_name: str):\n",
        "        \"\"\"Log memory usage for an operation.\"\"\"\n",
        "        # TODO: Implement memory logging\n",
        "        pass\n",
        "    \n",
        "    def reset(self):\n",
        "        \"\"\"Reset profiler state.\"\"\"\n",
        "        # TODO: Reset profiler\n",
        "        pass\n",
        "    \n",
        "    def get_peak_memory(self) -> float:\n",
        "        \"\"\"Get peak memory usage in MB.\"\"\"\n",
        "        # TODO: Return peak memory\n",
        "        pass\n",
        "\n",
        "class LargeNeuralNetwork(nn.Module):\n",
        "    \"\"\"\n",
        "    Memory-intensive neural network for profiling.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, input_size: int = 1000, hidden_sizes: List[int] = [2000, 2000, 2000], \n",
        "                 output_size: int = 100, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        # TODO: Implement large neural network\n",
        "        pass\n",
        "    \n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Forward pass without optimization.\"\"\"\n",
        "        # TODO: Implement forward pass\n",
        "        pass\n",
        "    \n",
        "    def forward_with_checkpointing(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Forward pass with gradient checkpointing.\"\"\"\n",
        "        # TODO: Implement checkpointed forward pass\n",
        "        pass\n",
        "\n",
        "def profile_network_memory(model: nn.Module, input_tensor: torch.Tensor, \n",
        "                          use_checkpointing: bool = False) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Profile memory usage of network forward pass.\n",
        "    \n",
        "    Args:\n",
        "        model: Neural network model\n",
        "        input_tensor: Input tensor\n",
        "        use_checkpointing: Whether to use gradient checkpointing\n",
        "        \n",
        "    Returns:\n",
        "        dict: Memory usage statistics\n",
        "    \"\"\"\n",
        "    # TODO: Implement memory profiling\n",
        "    pass\n",
        "\n",
        "def optimize_memory_usage(model: nn.Module, input_tensor: torch.Tensor) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Apply memory optimizations and measure improvement.\n",
        "    \n",
        "    Args:\n",
        "        model: Neural network model\n",
        "        input_tensor: Input tensor\n",
        "        \n",
        "    Returns:\n",
        "        dict: Optimization results\n",
        "    \"\"\"\n",
        "    # TODO: Implement memory optimizations\n",
        "    pass\n",
        "\n",
        "def compare_memory_strategies():\n",
        "    \"\"\"Compare different memory optimization strategies.\"\"\"\n",
        "    # TODO: Implement comparison\n",
        "    pass\n",
        "\n",
        "# Comprehensive Test Suite\n",
        "def test_memory_profiler():\n",
        "    \"\"\"Test memory profiler functionality.\"\"\"\n",
        "    print(\"Running memory profiler tests...\")\n",
        "    \n",
        "    # Test case 1: Basic profiler initialization\n",
        "    profiler = MemoryProfiler()\n",
        "    assert profiler.device in ['cpu', 'cuda'], f\"Invalid device: {profiler.device}\"\n",
        "    assert len(profiler.memory_log) == 0, \"Memory log should be empty initially\"\n",
        "    print(\"‚úì Test 1: Profiler initialization passed\")\n",
        "    \n",
        "    # Test case 2: Memory usage tracking\n",
        "    memory_usage = profiler.get_memory_usage()\n",
        "    assert isinstance(memory_usage, dict), \"Memory usage should return a dictionary\"\n",
        "    assert 'cpu_memory' in memory_usage, \"Should track CPU memory\"\n",
        "    if profiler.device == 'cuda':\n",
        "        assert 'gpu_memory' in memory_usage, \"Should track GPU memory\"\n",
        "    print(\"‚úì Test 2: Memory usage tracking passed\")\n",
        "    \n",
        "    # Test case 3: Memory logging\n",
        "    profiler.log_memory(\"test_operation\")\n",
        "    assert len(profiler.memory_log) == 1, \"Should log one operation\"\n",
        "    assert profiler.memory_log[0]['operation'] == \"test_operation\"\n",
        "    print(\"‚úì Test 3: Memory logging passed\")\n",
        "    \n",
        "    # Test case 4: Profiler reset\n",
        "    profiler.reset()\n",
        "    assert len(profiler.memory_log) == 0, \"Memory log should be empty after reset\"\n",
        "    assert profiler.peak_memory == 0, \"Peak memory should be reset\"\n",
        "    print(\"‚úì Test 4: Profiler reset passed\")\n",
        "    \n",
        "    print(\"üéâ Memory profiler tests passed!\")\n",
        "\n",
        "def test_neural_network():\n",
        "    \"\"\"Test neural network functionality.\"\"\"\n",
        "    print(\"\\nRunning neural network tests...\")\n",
        "    \n",
        "    # Test case 1: Network initialization\n",
        "    model = LargeNeuralNetwork(input_size=100, hidden_sizes=[50, 50], output_size=10)\n",
        "    assert model is not None, \"Model should be created\"\n",
        "    print(\"‚úì Test 1: Network initialization passed\")\n",
        "    \n",
        "    # Test case 2: Forward pass\n",
        "    input_tensor = torch.randn(4, 100)  # batch_size=4\n",
        "    output = model.forward(input_tensor)\n",
        "    assert output.shape == (4, 10), f\"Wrong output shape: {output.shape}\"\n",
        "    print(\"‚úì Test 2: Forward pass passed\")\n",
        "    \n",
        "    # Test case 3: Checkpointed forward pass\n",
        "    output_checkpointed = model.forward_with_checkpointing(input_tensor)\n",
        "    assert output_checkpointed.shape == (4, 10), f\"Wrong checkpointed output shape: {output_checkpointed.shape}\"\n",
        "    print(\"‚úì Test 3: Checkpointed forward pass passed\")\n",
        "    \n",
        "    # Test case 4: Gradient computation\n",
        "    loss = output.sum()\n",
        "    loss.backward()\n",
        "    \n",
        "    # Check that gradients are computed\n",
        "    for param in model.parameters():\n",
        "        assert param.grad is not None, \"Gradients should be computed\"\n",
        "    print(\"‚úì Test 4: Gradient computation passed\")\n",
        "    \n",
        "    print(\"üéâ Neural network tests passed!\")\n",
        "\n",
        "def test_memory_profiling():\n",
        "    \"\"\"Test memory profiling functionality.\"\"\"\n",
        "    print(\"\\nRunning memory profiling tests...\")\n",
        "    \n",
        "    # Test case 1: Basic profiling\n",
        "    model = LargeNeuralNetwork(input_size=50, hidden_sizes=[20, 20], output_size=5)\n",
        "    input_tensor = torch.randn(2, 50)  # Small batch\n",
        "    \n",
        "    results = profile_network_memory(model, input_tensor, use_checkpointing=False)\n",
        "    \n",
        "    assert 'peak_memory' in results, \"Results should contain peak_memory\"\n",
        "    assert 'memory_timeline' in results, \"Results should contain memory_timeline\"\n",
        "    assert results['peak_memory'] > 0, \"Peak memory should be positive\"\n",
        "    print(\"‚úì Test 1: Basic profiling passed\")\n",
        "    \n",
        "    # Test case 2: Checkpointed profiling\n",
        "    results_checkpointed = profile_network_memory(model, input_tensor, use_checkpointing=True)\n",
        "    \n",
        "    assert 'peak_memory' in results_checkpointed, \"Checkpointed results should contain peak_memory\"\n",
        "    assert results_checkpointed['peak_memory'] > 0, \"Checkpointed peak memory should be positive\"\n",
        "    print(\"‚úì Test 2: Checkpointed profiling passed\")\n",
        "    \n",
        "    # Test case 3: Memory optimization\n",
        "    optimization_results = optimize_memory_usage(model, input_tensor)\n",
        "    \n",
        "    assert 'baseline_memory' in optimization_results, \"Should contain baseline memory\"\n",
        "    assert 'optimized_memory' in optimization_results, \"Should contain optimized memory\"\n",
        "    assert 'improvement' in optimization_results, \"Should contain improvement percentage\"\n",
        "    print(\"‚úì Test 3: Memory optimization passed\")\n",
        "    \n",
        "    print(\"üéâ Memory profiling tests passed!\")\n",
        "\n",
        "def test_memory_optimization():\n",
        "    \"\"\"Test memory optimization strategies.\"\"\"\n",
        "    print(\"\\nRunning memory optimization tests...\")\n",
        "    \n",
        "    # Test case 1: Memory comparison\n",
        "    model = LargeNeuralNetwork(input_size=100, hidden_sizes=[50, 50], output_size=10)\n",
        "    input_tensor = torch.randn(8, 100)\n",
        "    \n",
        "    # Profile both approaches\n",
        "    baseline_results = profile_network_memory(model, input_tensor, use_checkpointing=False)\n",
        "    checkpointed_results = profile_network_memory(model, input_tensor, use_checkpointing=True)\n",
        "    \n",
        "    # Checkpointed should use less memory (or at least not more)\n",
        "    assert checkpointed_results['peak_memory'] <= baseline_results['peak_memory'] * 1.1, \\\n",
        "        \"Checkpointed should not use significantly more memory\"\n",
        "    print(\"‚úì Test 1: Memory comparison passed\")\n",
        "    \n",
        "    # Test case 2: Performance vs memory tradeoff\n",
        "    import time\n",
        "    \n",
        "    # Time both approaches\n",
        "    start_time = time.time()\n",
        "    _ = model.forward(input_tensor)\n",
        "    baseline_time = time.time() - start_time\n",
        "    \n",
        "    start_time = time.time()\n",
        "    _ = model.forward_with_checkpointing(input_tensor)\n",
        "    checkpointed_time = time.time() - start_time\n",
        "    \n",
        "    # Checkpointed might be slower due to recomputation\n",
        "    print(f\"Baseline time: {baseline_time:.4f}s, Checkpointed time: {checkpointed_time:.4f}s\")\n",
        "    print(\"‚úì Test 2: Performance vs memory tradeoff analyzed\")\n",
        "    \n",
        "    print(\"üéâ Memory optimization tests passed!\")\n",
        "\n",
        "def test_edge_cases():\n",
        "    \"\"\"Test edge cases and error handling.\"\"\"\n",
        "    print(\"\\nRunning edge cases tests...\")\n",
        "    \n",
        "    # Test case 1: Very small batch size\n",
        "    model = LargeNeuralNetwork(input_size=10, hidden_sizes=[5], output_size=2)\n",
        "    input_tensor = torch.randn(1, 10)  # Single sample\n",
        "    \n",
        "    results = profile_network_memory(model, input_tensor)\n",
        "    assert results['peak_memory'] > 0, \"Should handle single sample\"\n",
        "    print(\"‚úì Test 1: Single sample handling passed\")\n",
        "    \n",
        "    # Test case 2: Large batch size\n",
        "    input_tensor_large = torch.randn(100, 10)\n",
        "    results_large = profile_network_memory(model, input_tensor_large)\n",
        "    assert results_large['peak_memory'] > results['peak_memory'], \"Larger batch should use more memory\"\n",
        "    print(\"‚úì Test 2: Large batch handling passed\")\n",
        "    \n",
        "    # Test case 3: Different input sizes\n",
        "    model_different = LargeNeuralNetwork(input_size=20, hidden_sizes=[10], output_size=3)\n",
        "    input_tensor_different = torch.randn(4, 20)\n",
        "    \n",
        "    results_different = profile_network_memory(model_different, input_tensor_different)\n",
        "    assert results_different['peak_memory'] > 0, \"Should handle different input sizes\"\n",
        "    print(\"‚úì Test 3: Different input sizes passed\")\n",
        "    \n",
        "    print(\"üéâ Edge cases tests passed!\")\n",
        "\n",
        "def test_benchmarking():\n",
        "    \"\"\"Test benchmarking and comparison functionality.\"\"\"\n",
        "    print(\"\\nRunning benchmarking tests...\")\n",
        "    \n",
        "    # Test case 1: Strategy comparison\n",
        "    try:\n",
        "        comparison_results = compare_memory_strategies()\n",
        "        assert isinstance(comparison_results, dict), \"Should return comparison results\"\n",
        "        print(\"‚úì Test 1: Strategy comparison passed\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  Strategy comparison test failed: {e}\")\n",
        "    \n",
        "    # Test case 2: Performance metrics\n",
        "    model = LargeNeuralNetwork(input_size=50, hidden_sizes=[25], output_size=5)\n",
        "    input_tensor = torch.randn(4, 50)\n",
        "    \n",
        "    results = profile_network_memory(model, input_tensor)\n",
        "    \n",
        "    # Verify all expected metrics are present\n",
        "    expected_metrics = ['peak_memory', 'memory_timeline', 'operations']\n",
        "    for metric in expected_metrics:\n",
        "        assert metric in results, f\"Missing metric: {metric}\"\n",
        "    \n",
        "    print(\"‚úì Test 2: Performance metrics passed\")\n",
        "    \n",
        "    print(\"üéâ Benchmarking tests passed!\")\n",
        "\n",
        "# Test the implementation\n",
        "if __name__ == \"__main__\":\n",
        "    # Run all tests\n",
        "    test_memory_profiler()\n",
        "    test_neural_network()\n",
        "    test_memory_profiling()\n",
        "    test_memory_optimization()\n",
        "    test_edge_cases()\n",
        "    test_benchmarking()\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"Running full memory profiling example...\")\n",
        "    \n",
        "    # Create model and test data\n",
        "    model = LargeNeuralNetwork()\n",
        "    input_tensor = torch.randn(32, 1000)  # batch_size=32\n",
        "    \n",
        "    print(\"Profiling memory usage...\")\n",
        "    \n",
        "    # Profile without optimization\n",
        "    results_baseline = profile_network_memory(model, input_tensor, use_checkpointing=False)\n",
        "    print(f\"Baseline memory usage: {results_baseline['peak_memory']:.2f} MB\")\n",
        "    \n",
        "    # Profile with optimization\n",
        "    results_optimized = profile_network_memory(model, input_tensor, use_checkpointing=True)\n",
        "    print(f\"Optimized memory usage: {results_optimized['peak_memory']:.2f} MB\")\n",
        "    \n",
        "    # Calculate improvement\n",
        "    improvement = (results_baseline['peak_memory'] - results_optimized['peak_memory']) / results_baseline['peak_memory']\n",
        "    print(f\"Memory reduction: {improvement:.1%}\")\n",
        "    \n",
        "    print(\"\\nüéâ All memory profiling tests completed successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üí° Hints\n",
        "\n",
        "<details>\n",
        "<summary>Click to reveal hint for Question 1: Memory-Efficient Prefix Sum</summary>\n",
        "\n",
        "**Hint**: For in-place prefix sum, you need to iterate through the array once and update each element to be the sum of all previous elements plus itself. Start from index 1 (since index 0 doesn't need to change) and for each position i, set `arr[i] = arr[i-1] + arr[i]`.\n",
        "\n",
        "**Key insight**: Each element becomes the sum of all elements from the beginning up to and including itself.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Click to reveal hint for Question 2: Tensor Operation Benchmarking</summary>\n",
        "\n",
        "**Hint**: For the loop version, use a simple for loop with indexing. For the vectorized version, use NumPy's built-in multiplication operator. Use `time.time()` to measure execution time and `tracemalloc` to track memory usage. Create arrays of different sizes and measure both time and memory for each approach.\n",
        "\n",
        "**Key insight**: Vectorized operations should be significantly faster due to SIMD instructions and reduced Python overhead.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Click to reveal hint for Question 3: Cache-Aware Matrix Operations</summary>\n",
        "\n",
        "**Hint**: For tiling, divide the matrices into smaller blocks (tiles) and process them separately. This improves cache locality by keeping frequently accessed data in cache. The tile size should be chosen based on cache size (typically 64x64 or 128x128). For Numba, use the `@jit(nopython=True)` decorator to compile the function.\n",
        "\n",
        "**Key insight**: Tiling reduces cache misses by ensuring that when you access a tile, all its data fits in cache.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Click to reveal hint for Question 4: Custom Sparse Tensor Operations</summary>\n",
        "\n",
        "**Hint**: In COO format, store non-zero values and their coordinates separately. For addition, you need to merge the coordinate lists and sum values at the same coordinates. For element-wise multiplication, only multiply values that exist in both tensors. For reshaping, convert 1D coordinates to multi-dimensional coordinates.\n",
        "\n",
        "**Key insight**: Sparse operations should only work on non-zero elements, making them much more memory-efficient for sparse data.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Click to reveal hint for Question 5: Memory Profiling and Optimization</summary>\n",
        "\n",
        "**Hint**: Use `torch.cuda.memory_allocated()` and `torch.cuda.max_memory_allocated()` for GPU memory tracking. For gradient checkpointing, use `torch.utils.checkpoint.checkpoint()` to trade compute for memory. Implement the network with multiple large layers and measure memory usage at each step.\n",
        "\n",
        "**Key insight**: Gradient checkpointing saves memory by recomputing activations during backward pass instead of storing them during forward pass.\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
